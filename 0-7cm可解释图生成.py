# -*- coding: utf-8 -*-
"""
Created on Mon Nov 17 20:06:06 2025

@author: fupf
"""
# -*- coding: utf-8 -*-
"""
Created on Thu Oct 23 08:42:05 2025

@author: fupf
"""
import os
import numpy as np

# import seaborn as sns
import matplotlib.pyplot as plt
# import seaborn as sns
# from osgeo import gdal
import pandas as pd
# from datetime import datetime,timedelta
import xgboost as xgb
from math import sqrt
# from sklearn.cluster import KMeans
# import shappry
import shap
import warnings
from matplotlib.ticker import FormatStrFormatter
# import scipy.signal
# import matplotlib.colors as mcolors
from scipy.interpolate import make_interp_spline
# LightGBM æ¨¡å‹è®­ç»ƒï¼ˆæ­£ç¡®ä½¿ç”¨æ—©åœï¼‰
# from lightgbm import early_stopping, log_evaluation
warnings.filterwarnings('ignore')
#%%

data_path=r'G:\Data\é™æ°´å’ŒåœŸå£¤æ°´åˆ†æ•°æ®æå–\2021å¹´1-12æœˆè€•åœ°é™æ°´å’Œdelta_smçš„æ•°æ®\æ•°æ®æå–\å…¨å›½æ•°æ®\2017-2022\æ¨¡å‹æ¨¡æ‹Ÿæ•°æ®\0~7cm\åœŸå£¤åˆ†ç±»\æ•°æ®\0~7cmå…¨å›½9å¤§å†œä¸šåˆ†åŒº40ä¸ªåœ°å½¢è´¨åœ°åˆ†ç±»æ•°æ®.csv'
out_path=r'G:\Data\é™æ°´å’ŒåœŸå£¤æ°´åˆ†æ•°æ®æå–\2021å¹´1-12æœˆè€•åœ°é™æ°´å’Œdelta_smçš„æ•°æ®\æ•°æ®æå–\å…¨å›½æ•°æ®\2017-2022\æ¨¡å‹æ¨¡æ‹Ÿæ•°æ®\0~7cm\åœŸå£¤åˆ†ç±»\è®­ç»ƒç»“æœ\ã€æ–°ã€‘40ä¸ªåœŸå£¤åˆ†ç±»ä¸­æŒ‘é€‰15ä¸ªä¸»è¦ç±»å‹è´¡çŒ®ç»“æœ'
out_path1=r'G:\Data\é™æ°´å’ŒåœŸå£¤æ°´åˆ†æ•°æ®æå–\2021å¹´1-12æœˆè€•åœ°é™æ°´å’Œdelta_smçš„æ•°æ®\æ•°æ®æå–\å…¨å›½æ•°æ®\2017-2022\æ¨¡å‹æ¨¡æ‹Ÿæ•°æ®\0~7cm\åœŸå£¤åˆ†ç±»\è®­ç»ƒç»“æœ\V2_40ä¸ªåœŸå£¤åˆ†ç±»ä¸­æŒ‘é€‰15ä¸ªä¸»è¦ç±»å‹è´¡çŒ®ç»“æœ'
data_info_path=r'G:\Data\é™æ°´å’ŒåœŸå£¤æ°´åˆ†æ•°æ®æå–\2021å¹´1-12æœˆè€•åœ°é™æ°´å’Œdelta_smçš„æ•°æ®\æ•°æ®æå–\å…¨å›½æ•°æ®\2017-2022\æ¨¡å‹æ¨¡æ‹Ÿæ•°æ®\0~7cm\åœŸå£¤åˆ†ç±»\æ•°æ®\0~7cmä¸åŒå†œä¸šåˆ†åŒºä¸‹åœ°å½¢è´¨åœ°åˆ†ç±»ç»Ÿè®¡ç»“æœ.xlsx'

data_info=pd.read_excel(data_info_path)
data_info_tiqu=data_info['åœŸå£¤åˆ†ç±»'].tolist()[0:15] #98.17%
threshold=data_info.iloc[14,1]

all_data_reclass1=pd.read_csv(data_path)

all_data_reclass1['evaporation']=all_data_reclass1['evaporation']*1000
all_data_reclass1['ERA5_precipitation']=all_data_reclass1['ERA5_precipitation']*1000
all_data_reclass1=all_data_reclass1[(all_data_reclass1['ERA5_start_soil']>=0) 
                                    ]


all_data_reclass1=all_data_reclass1.rename(
    columns={'ERA5_precipitation':'TP',#total precipitation/m
             'ERA5_start_soil':'ASML1',#antecedent soil moisture/m3m-3
             'ERA5_delta_soil':'DSML1',#delta_soil_moisture/m3m-3
             'soil_temperature':'STL1',#Soil temperature level 1/K
             'evaporation':'TE',#total Evaporation/mm of water equivalent
             'EVI-day':'EVI',
             'NDVI-day':'NDVI',
             'leaf_area_index_low_vegetation':'LAI',#leaf_area_index_low_vegetation/m2m-2
             'pressure':'SP',#surface_pressure/Pa
             'temperature':'T2M',#2m temperature/K
             'wind_u':'WU10M',#10m_u_component_of_wind/ms-1
             'wind_v':'WV10M',#10m_V_component_of_wind/ms-1
             
             })

parameters = [
              'TP','ASML1', 'DSML1',
              'STL1','TE', 
              'EVI', 'NDVI','LAI',
               'SP','T2M', 'WU10M', 'WV10M',
              'BD','POROSITY'
              ]


all_data_reclass1['TM'] = pd.to_datetime(all_data_reclass1['TM'], format='%Y_%m_%d', errors='coerce')
all_data_reclass1['month'] = all_data_reclass1['TM'].dt.month





# joint_class='Silty Clay Loam_1'
# éå†æ¯ä¸ªåˆ†ç±»
for joint_class in data_info_tiqu:
    print(f"  å¤„ç†åˆ†ç±»: {joint_class}")
    
    joint_class='Loam_1'
    
    # æ„å»ºå®Œæ•´è¾“å‡ºè·¯å¾„
    full_dir = os.path.join(out_path1, joint_class)
    
    # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å·²å­˜åœ¨
    # if os.path.exists(full_dir):
    #     print(f"æ–‡ä»¶å¤¹ '{full_dir}' å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†ã€‚")
    #     continue  # è·³è¿‡æœ¬æ¬¡å¾ªç¯ï¼Œä¸å¤„ç†è¯¥åˆ†ç±»
    
    # æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
    os.makedirs(full_dir)
    print(f"æ–‡ä»¶å¤¹ '{full_dir}' å·²åˆ›å»ºã€‚")
    # å­˜å‚¨æ‰€æœ‰æœ€ä¼˜å‚æ•°å’Œè¯„ä¼°ç»“æœ
    all_best_params_df = []
    
    
    class_data = all_data_reclass1[all_data_reclass1['joint_class'] == joint_class]
    
    # è·å–æ‰€æœ‰ fenqu_ID
    fenqu_ids = sorted(class_data['fenqu_ID'].unique())
    
    # å¤–å±‚å¾ªç¯ï¼šéå†æ¯ä¸ªåˆ†åŒº
    for fenqu_id in fenqu_ids:
        print(f"\n=== å¤„ç†åˆ†åŒº {fenqu_id} ===")
        fenqu_id=1.0
        
        # æå–å½“å‰åˆ†åŒºæ•°æ®
        fenqu_data = class_data[class_data['fenqu_ID'] == int(fenqu_id)]
        
        # å¦‚æœæ ·æœ¬å¤ªå°‘ï¼Œè·³è¿‡ï¼ˆé¿å…äº¤å‰éªŒè¯å¤±è´¥ï¼‰
        if len(fenqu_data) < threshold:
            print("æ ·æœ¬æ•°ä¸è¶³ï¼Œè·³è¿‡...")
            continue
        #shapè®¡ç®—æ ·æœ¬æ•°æ®
        sample_df = fenqu_data.sample(frac=0.2, random_state=42, replace=False)
    
    
        full_df_path=out_path+'\\{}'.format(joint_class)+'\\åˆ†åŒº{}åœŸå£¤åˆ†ç±»{}_æµ‹è¯•é›†SHAPå€¼.csv'.format(fenqu_id,joint_class)
        
        full_df=pd.read_csv(full_df_path)
        
        # =====================================
        # ğŸ” ä½¿ç”¨ SHAP è¿›è¡Œè´¡çŒ®åˆ†æ
        # =====================================
        columns = [
                      'TP','ASML1', 
                      'STL1','TE', 
                      'EVI', 'NDVI','LAI',
                       'SP','T2M', 
                       'WU10M', 'WV10M',
                      'BD','POROSITY'
                      ]
        
        shap_columns = [f"shap_{col}" for col in columns]
        full_df_tiqu = full_df[shap_columns]
        full_df_tiqu_numpy = full_df[shap_columns].to_numpy()
        
        shap_values = full_df_tiqu_numpy
    
        result = full_df_tiqu.abs().mean()
    
    
    
        import matplotlib as mpl

        mpl.rcParams['font.family'] = 'Times New Roman'
        # mpl.rcParams['mathtext.fontset'] = 'custom'
        mpl.rcParams['mathtext.rm'] = 'Times New Roman'
        mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'
        mpl.rcParams['mathtext.bf'] = 'Times New Roman:bold'

    
        plt.rcParams["axes.unicode_minus"] = False  # é˜²æ­¢è´Ÿå·æ˜¾ç¤ºå¼‚å¸¸
        # å…¨å±€è®¾ç½® Times New Roman å­—ä½“
        plt.rcParams['text.usetex'] = False  # ç¡®ä¿ä¸ä½¿ç”¨ LaTeXï¼ˆé™¤éä½ æœ‰éœ€æ±‚ï¼‰
        
        
        # 1. ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾ï¼ˆå…¨å±€è§£é‡Šï¼‰#################################
        fig=plt.figure(figsize=(8, 8))
        # ç›´æ¥ç»˜åˆ¶æ¡å½¢å›¾ï¼Œä¸æ¥æ”¶è¿”å›å€¼ï¼ˆå› ä¸ºå®ƒå¯èƒ½æ˜¯ Noneï¼‰
        shap.summary_plot(shap_values, sample_df[columns], plot_type="bar", show=False)
        
        # ä½¿ç”¨ gca() è·å–å½“å‰åæ ‡è½´
        ax = plt.gca()
        
        # === å…³é—­ç½‘æ ¼çº¿ ===
        ax.grid(False)
        
        # === è®¾ç½®å››å‘¨è¾¹æ¡†é¢œè‰²å’Œç²—ç»† ===
        for spine in ['top', 'right', 'left', 'bottom']:
            ax.spines[spine].set_visible(True)
            ax.spines[spine].set_color('black')      # æ›´æ˜ç¡®çš„é¢œè‰²è®¾ç½®
            ax.spines[spine].set_linewidth(2)        # è®¾ç½®çº¿å®½ä¸º1
        
        # === è®¾ç½®æ ‡ç­¾å’Œå­—ä½“åŠ ç²— ===
        # ax.set_xlabel("Mean |SHAP Value|", fontsize=26, fontweight='bold')
        # ax.set_ylabel("Features", fontsize=26, fontweight='bold')
        
        ax.set_xlabel("")   # æ¸…ç©º x è½´æ ‡é¢˜
        ax.set_ylabel("")   # æ¸…ç©º y è½´æ ‡é¢˜
        
        ax.text(0.95, 0.05, joint_class, 
                transform=ax.transAxes,
                fontsize=32,
                fontweight='bold',
                fontname='Times New Roman',
                verticalalignment='bottom',
                horizontalalignment='right',
                color='black')
        
        ax.xaxis.set_major_formatter(FormatStrFormatter('%.3f'))

        # === è®¾ç½®åˆ»åº¦æ ‡ç­¾å¤§å°å’ŒåŠ ç²— ===
        ax.tick_params(axis='both', which='major', labelsize=20, width=1, color='black')
        ax.tick_params(axis='y', which='major', labelsize=20, width=1, color='black')
        
        # é‡æ–°è®¾ç½® y è½´æ ‡ç­¾ä»¥æ”¯æŒ fontweight
        y_labels = [label.get_text() for label in ax.get_yticklabels()]
        ax.set_yticklabels(y_labels, fontsize=30, fontweight='bold')
        
        # å¯é€‰ï¼šx è½´æ ‡ç­¾ä¹ŸåŠ ç²—
        x_labels = [label.get_text() for label in ax.get_xticklabels()]
        ax.set_xticklabels(x_labels, fontsize=30, fontweight='bold',rotation=45)
        ax.xaxis.set_label_coords(0.5, -0.15)  # è°ƒæ•´ -0.15 åˆ°ä½ æƒ³è¦çš„ç¡®åˆ‡ä½ç½®
        
        # === è°ƒæ•´å¸ƒå±€å¹¶æ˜¾ç¤º ===
        plt.tight_layout()
        # plt.show()
        plt.savefig(out_path1+'\\{}'.format(joint_class)+"\\åˆ†åŒº{}åœŸå£¤åˆ†ç±»{}_delta_sm_bar.png".format(fenqu_id,joint_class), dpi=300, bbox_inches='tight')
        plt.close()       
        
        
    
    
        pre_name='TP'
        soil_name='ASML1'
        st_name='STL1'
        
        # å‡å®š shap_values æ˜¯ä¸€ä¸ªäºŒç»´æ•°ç»„ï¼Œæ¯ä¸ªç‰¹å¾å¯¹åº”ä¸€è¡Œã€‚
        sorted_idx = result.argsort()[::-1]  # æ ¹æ®é‡è¦æ€§å¯¹ç‰¹å¾è¿›è¡Œé™åºæ’åˆ—
        
        # æå–æœ€é‡è¦çš„ä¸¤ä¸ªç‰¹å¾
        top_features = [columns[i] for i in sorted_idx[:5]]
        
        # pre_name=top_features[0]
        # soil_name=top_features[1]
        
        
        
        
        
        # 4.è´¡çŒ®æœ€å¤§5ä¸ªè¦ç´ tipping######################################
        
        # -----------------------------
        # æ•°æ®é¢„å¤„ç†ï¼šæŒ‰ 'ERA5_precipitation' åˆ†ç»„ç»Ÿè®¡
        # -----------------------------
        def plot_shap_scatter_by_value_col(
            full_df,
            value_col,
            fenqu_id,
            joint_class,
            out_path,
            bin_size=10,
            threshold=30
        ):
            """
            æ ¹æ®æŒ‡å®šçš„ value_col å¯¹æ•°æ®è¿›è¡Œåˆ†ç»„ã€ç­›é€‰æ˜¾è‘—åŒºé—´ï¼Œå¹¶ç»˜åˆ¶ SHAP å€¼æ•£ç‚¹å¹³æ»‘å›¾ï¼Œ
            ä¿å­˜ä¸º PNG æ–‡ä»¶ï¼Œæ–‡ä»¶åå’Œæ¨ªè½´æ ‡ç­¾æ ¹æ® value_col åŠ¨æ€è°ƒæ•´ã€‚
        
            å‚æ•°:
                full_df (pd.DataFrame): åŒ…å« 'shap_{value_col}' å’Œ {value_col} åˆ—çš„ DataFrame
                value_col (str): è¦åˆ†æçš„å˜é‡åˆ—åï¼ˆå¦‚ 'TP', 'STL2' ç­‰ï¼‰
                fenqu_id (str or int): åˆ†åŒº ID
                joint_class (str): åœŸå£¤åˆ†ç±»åç§°
                out_path (str): è¾“å‡ºç›®å½•è·¯å¾„
                bin_size (int): åˆå§‹åˆ†ç»„ bin å¤§å°ï¼Œé»˜è®¤ 20
                threshold (int): æ˜¾è‘—ç»„æœ€å°æ ·æœ¬æ•°é˜ˆå€¼ï¼Œé»˜è®¤ 30
            """
            
            # -----------------------------
            # Step 1: å®šä¹‰æ¨ªåæ ‡æ ‡ç­¾æ˜ å°„
            # -----------------------------
            xlabel_map = {
                'TP': 'Precipitation(mm)',
                'STL1': 'Soil Temperature(K)',
                'TE': 'Evaporation(mm)',
                'ASML1': r"Soil Moisture (m$^{3}$Â·m$^{-3}$)",
                'T2M': '2m Temperature(K)',
                'WU10M':r'10m_u_component_of_wind(mÂ·s$^{-1}$)',
                'WV10M':r'10m_v_component_of_wind(mÂ·s$^{-1}$)',
                'SP':'Surface Pressure(Pa)',
                'LAI':r'Leaf Area Index(m$^{2}$Â·s$^{-2}$)',
                'BD':r'Bulk Density(gÂ·cm$^{-3}$)',
                'POROSITY':'Porosity(%)',
                'EVI':'Enhanced Vegetation Index',
                'NDVI':'Normalized Difference Vegetation Index'
            }
        
        
            xlabel = xlabel_map.get(value_col, f'{value_col}')  # é»˜è®¤ç”¨åˆ—å
        
            # -----------------------------
            # Step 2: æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            # -----------------------------
            if value_col not in full_df.columns:
                raise ValueError(f"åˆ— '{value_col}' ä¸å­˜åœ¨äº DataFrame ä¸­")
            shap_col = f'shap_{value_col}'
            if shap_col not in full_df.columns:
                raise ValueError(f"åˆ— '{shap_col}' ä¸å­˜åœ¨äº DataFrame ä¸­")
        
        
            # -----------------------------
            # Step 3: ç­›é€‰æ˜¾è‘—åˆ†ç»„
            # -----------------------------
            def filter_df_by_significant_groups(df, col, bin_size, threshold):
                
                # max_val = full_df[value_col].max()
                
                max_val = df[col].max()
                upper_bound = (int(max_val) // bin_size + 1) * bin_size
                bins = list(range(0, upper_bound + 1, bin_size))
                labels = [f'{i}-{i+bin_size}' for i in bins[:-1]]
                bin_labels = pd.cut(
                    df[col],
                    bins=bins,
                    labels=labels,
                    right=False,
                    include_lowest=True
                )
                group_counts = bin_labels.value_counts().sort_index()
                significant_groups = group_counts[group_counts > threshold].index
                filtered_df = df[bin_labels.isin(significant_groups)].copy()
                filtered_df['group'] = bin_labels[bin_labels.isin(significant_groups)]
                return filtered_df, significant_groups
        
            filtered_df, significant_groups = filter_df_by_significant_groups(full_df, value_col, bin_size, threshold)
        
            if filtered_df.empty:
                print(f"è­¦å‘Šï¼š{value_col} åœ¨åˆ†åŒº {fenqu_id}, ç±»åˆ« {joint_class} ä¸‹æ— æ˜¾è‘—åˆ†ç»„ï¼Œè·³è¿‡ç»˜å›¾ã€‚")
                return
        
            # -----------------------------
            # Step 4: è¿›ä¸€æ­¥ç»†åˆ†ä¸º bins å¹¶è®¡ç®—ç»Ÿè®¡é‡
            # -----------------------------
            num_bins = len(significant_groups) * 10
            filtered_df['bin'] = pd.cut(filtered_df[value_col], bins=num_bins, labels=False)
            bin_centers = filtered_df.groupby('bin')[value_col].mean()
            bin_mean = filtered_df.groupby('bin')[shap_col].mean()
            bin_upper = filtered_df.groupby('bin')[shap_col].quantile(0.9)
            bin_lower = filtered_df.groupby('bin')[shap_col].quantile(0.1)
        
            bin_upper = bin_upper.reindex(bin_centers.index)
            bin_lower = bin_lower.reindex(bin_centers.index)
        
        
            # -----------------------------
            # Step 6: å¹³æ»‘æ›²çº¿
            # -----------------------------
            X_smooth = np.linspace(bin_centers.min(), bin_centers.max(), 300)
            spl_mean = make_interp_spline(bin_centers, bin_mean, k=3)
            spl_upper = make_interp_spline(bin_centers, bin_upper, k=3)
            spl_lower = make_interp_spline(bin_centers, bin_lower, k=3)
            
            Y_mean_smooth = spl_mean(X_smooth)
            Y_upper_smooth = spl_upper(X_smooth)
            Y_lower_smooth = spl_lower(X_smooth)
            
            # æ‰¾å‡ºæ‰€æœ‰ Y_mean_smooth ç©¿è¿‡ 0 çš„ä½ç½®ï¼ˆåŒ…æ‹¬ä»æ­£åˆ°è´Ÿã€è´Ÿåˆ°æ­£ï¼‰
            def find_zero_crossings(x, y):
                """
                æ‰¾åˆ° y=0 çš„æ‰€æœ‰äº¤ç‚¹ï¼ˆé€šè¿‡ç¬¦å·å˜åŒ– + çº¿æ€§æ’å€¼ï¼‰
                è¿”å›ï¼šäº¤ç‚¹ x åæ ‡åˆ—è¡¨
                """
                # ç§»é™¤ NaNï¼ˆè™½ç„¶å¹³æ»‘åä¸€èˆ¬æ²¡æœ‰ï¼Œä½†ä¿é™©èµ·è§ï¼‰
                valid = ~np.isnan(y)
                x = x[valid]
                y = y[valid]
                
                # æ‰¾å‡ºç¬¦å·å˜åŒ–çš„ä½ç½®ï¼ˆy[i] * y[i+1] < 0ï¼‰
                sign_changes = np.where(np.sign(y[:-1]) * np.sign(y[1:]) < 0)[0]
                
                crossings = []
                for i in sign_changes:
                    # çº¿æ€§æ’å€¼ä¼°è®¡é›¶ç‚¹
                    x1, x2 = x[i], x[i+1]
                    y1, y2 = y[i], y[i+1]
                    # é¿å…é™¤é›¶ï¼ˆç†è®ºä¸Šä¸ä¼šï¼Œå› ç¬¦å·ä¸åŒï¼‰
                    if y2 != y1:
                        x_zero = x1 - y1 * (x2 - x1) / (y2 - y1)
                        crossings.append(x_zero)
                
                # å¯é€‰ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ y ç²¾ç¡®ç­‰äº 0 çš„ç‚¹ï¼ˆç½•è§ï¼Œä½†å¯åŠ ï¼‰
                exact_zeros = x[np.isclose(y, 0, atol=1e-12)]
                crossings.extend(exact_zeros)
                
                # å»é‡å¹¶æ’åº
                crossings = sorted(set(crossings))
                return crossings
            
            # è°ƒç”¨å‡½æ•°
            cross_x_list = find_zero_crossings(X_smooth, Y_mean_smooth)
            
            # -----------------------------
            # Step 7: ç»˜å›¾
            # -----------------------------
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # 1. ç°è‰²å¡«å……ï¼šä¸Šä¸‹ç•Œä¹‹é—´ï¼ˆä¸ç¡®å®šæ€§å¸¦ï¼‰
            ax.fill_between(X_smooth, Y_lower_smooth, Y_upper_smooth, color='gray', alpha=0.2)
            
            # 2. ç»˜åˆ¶å¹³æ»‘æ›²çº¿
            ax.plot(X_smooth, Y_mean_smooth, color='blue', linewidth=2, label='SHAP mean value')
            ax.plot(X_smooth, Y_upper_smooth, color='gray', linewidth=1)
            ax.plot(X_smooth, Y_lower_smooth, color='gray', linewidth=1)
            
            for idx, cross_x in enumerate(cross_x_list):
                
                # 3. çº¢è‰²å‚ç›´çº¿ï¼šcross_x
                ax.axvline(x=cross_x, color='red', linestyle='--', linewidth=1.5)
                
                # 5. æ ‡è®°äº¤ç‚¹
                ax.plot(cross_x, 0, 'ro', markersize=10, label='Tipping point')
            
                # åŠ¨æ€è®¡ç®—æ–‡æœ¬åç§»é‡ï¼Œä½¿å¾—æ ‡ç­¾ä¸äº’ç›¸é®ç›–
                # å¯ä»¥æ ¹æ®å®é™…éœ€è¦è°ƒæ•´ä¸‹é¢çš„æ•°å­—
                x_offset = (-40 if idx % 2 == 0 else -80)  # å·¦å³äº¤æ›¿ç§»åŠ¨
                y_offset = (50 if idx % 2 == 0 else -50)  # æŒ‰ç…§ç´¢å¼•å¢åŠ yæ–¹å‘çš„åç§»ï¼Œé˜²æ­¢ä¸Šä¸‹é‡å 
                
                # 6. æ·»åŠ æ³¨é‡Šï¼ˆæ•°å€¼æ ‡ç­¾ï¼‰
                ax.annotate(f'{cross_x:.2f}',
                            xy=(cross_x, 0),
                            xytext=(x_offset, y_offset),  # åŠ¨æ€è®¡ç®—åç§»
                            textcoords='offset points',
                            arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=.5", color='k', lw=2),
                            fontsize=30, color='k', fontweight='bold')
            
            # 4. æ¨ªè½´é›¶çº¿
            ax.axhline(y=0, color='black', linestyle='--', linewidth=1.5)
            
            # 7. åˆ†åŒºåŸŸå¡«å……ï¼šå·¦ä¾§è´Ÿè´¡çŒ®ï¼ˆç²‰çº¢ï¼‰ï¼Œå³ä¾§æ­£è´¡çŒ®ï¼ˆè“è‰²ï¼‰
            # --- å·¦ä¾§ï¼šbin_centers < cross_x ä¸” bin_mean < 0 â†’ å¡«å……åˆ° y=0
            left_mask = (Y_mean_smooth < 0)
            if np.any(left_mask):
                ax.fill_between(X_smooth[left_mask], Y_mean_smooth[left_mask], 0,
                                facecolor='pink', alpha=0.6, label='Negative Region', interpolate=True)
            
            # --- å³ä¾§ï¼šbin_centers > cross_x ä¸” bin_mean > 0 â†’ å¡«å……åˆ° y=0
            right_mask = (Y_mean_smooth > 0)
            if np.any(right_mask):
                ax.fill_between(X_smooth[right_mask], Y_mean_smooth[right_mask], 0,
                                facecolor='lightblue', alpha=0.6, label='Positive Region', interpolate=True)
            
            # 8. ç¾åŒ–
            ax.grid(False)
            for spine in ['top', 'right', 'left', 'bottom']:
                ax.spines[spine].set_visible(True)
                ax.spines[spine].set_color('black')
                ax.spines[spine].set_linewidth(2)
            
            # ax.set_xlabel(xlabel, fontsize=30, fontweight='bold')
            # ax.set_ylabel('SHAP Value', fontsize=30, fontweight='bold')
            
            ax.set_xlabel("")   # æ¸…ç©º x è½´æ ‡é¢˜
            ax.set_ylabel("")   # æ¸…ç©º y è½´æ ‡é¢˜
            
            ax.text(0.95, 0.05, joint_class, 
                    transform=ax.transAxes,
                    fontsize=32,
                    fontweight='bold',
                    fontname='Times New Roman',
                    verticalalignment='bottom',
                    horizontalalignment='right',
                    color='black')
            
            # è·å–å½“å‰æ‰€æœ‰å¥æŸ„å’Œæ ‡ç­¾
            handles, labels = ax.get_legend_handles_labels()
            
            # ä½¿ç”¨ dict ä¿æŒé¡ºåºå¹¶å»é‡ï¼ˆPython 3.7+ å­—å…¸æœ‰åºï¼‰
            # by_label = dict(zip(labels, handles))
            
            # å›¾ä¾‹ä¸æ˜¾ç¤º
            ax.legend().set_visible(False)
            
            # é‡æ–°è®¾ç½®å›¾ä¾‹
            # ax.legend(by_label.values(), by_label.keys(), fontsize=20, ncol=4, bbox_to_anchor=(0.5, -0.1), loc='upper center')
            # ax.legend(by_label.values(), by_label.keys(),fontsize=20)
            # ax.legend(fontsize=20)
            plt.xticks(fontsize=30, fontweight='bold')
            plt.yticks(fontsize=30, fontweight='bold')
            plt.tight_layout()
        
            # -----------------------------
            # Step 8: ä¿å­˜å›¾ç‰‡
            # -----------------------------
            save_dir = os.path.join(out_path1, str(joint_class))
            os.makedirs(save_dir, exist_ok=True)
            filename = "åˆ†åŒº{}åœŸå£¤åˆ†ç±»{}_{}_delta_sm_scatter.png".format(fenqu_id, joint_class, value_col)
            save_path = os.path.join(save_dir, filename)
            plt.savefig(save_path, dpi=600, bbox_inches='tight')
            plt.close()
        
            print("âœ… å·²ä¿å­˜ ")
        
        
        for para in top_features:
        
            plot_shap_scatter_by_value_col(
                full_df,
                para,
                fenqu_id,
                joint_class,
                out_path,
                bin_size=10,
                threshold=30
            )
        
        
        
        
        # 6.ç¬¬äºŒä¸ªä¾èµ–å›¾ï¼Œä½¿ç”¨ 'ERA5_start_soil' ä½œä¸ºäº¤äº’å˜é‡ ################
        plt.figure(figsize=(8, 8))  # å†æ¬¡è°ƒæ•´å›¾è¡¨å¤§å°
        shap.dependence_plot(soil_name, shap_values, sample_df[columns], interaction_index=st_name, show=False)
        
        # ä½¿ç”¨ gca() è·å–å½“å‰åæ ‡è½´
        ax = plt.gca()
        
        # === å…³é—­ç½‘æ ¼çº¿ ===
        ax.grid(False)
        
        # === è®¾ç½®å››å‘¨è¾¹æ¡†é¢œè‰²å’Œç²—ç»† ===
        for spine in ['top', 'right', 'left', 'bottom']:
            ax.spines[spine].set_visible(True)
            ax.spines[spine].set_color('black')      # æ›´æ˜ç¡®çš„é¢œè‰²è®¾ç½®
            ax.spines[spine].set_linewidth(2)        # è®¾ç½®çº¿å®½ä¸º1
        
        # è®¾ç½®æ ‡é¢˜å’Œåæ ‡è½´æ ‡ç­¾
        # plt.title("SHAP Dependence Plot for ERA5_precipitation with Interaction of ERA5_start_soil", fontsize=14)
        # plt.xlabel('Precipitation(mm)', fontsize=18, fontweight='bold')
        # plt.ylabel("SHAP Value", fontsize=18, fontweight='bold')
        
        ax.set_xlabel("")   # æ¸…ç©º x è½´æ ‡é¢˜
        ax.set_ylabel("")   # æ¸…ç©º y è½´æ ‡é¢˜
        # è®¾ç½®åæ ‡è½´åˆ»åº¦å’Œç½‘æ ¼çº¿
        plt.xticks(fontsize=30, fontweight='bold',rotation=45)
        plt.yticks(fontsize=30, fontweight='bold')
        # plt.grid(True, linestyle='--', alpha=0.7)
        ax.text(0.95, 0.05, joint_class, 
                transform=ax.transAxes,
                fontsize=32,
                fontweight='bold',
                fontname='Times New Roman',
                verticalalignment='bottom',
                horizontalalignment='right',
                color='black')
        # === å…³é”®ï¼šè·å– colorbar å¹¶è®¾ç½®å­—ä½“ ===
       
        # ä¾èµ–å›¾é€šå¸¸ä¼šæ·»åŠ ä¸€ä¸ª colorbarï¼Œå®ƒæ˜¯ fig.axes çš„æœ€åä¸€ä¸ª
        if len(plt.gcf().axes) > 1:
            cbar_ax = plt.gcf().axes[-1]
            
            # === å…³é”®ï¼šè®¾ç½® colorbar åˆ»åº¦å€¼ä¿ç•™ 2 ä½å°æ•° ===
            cbar_ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))
            
            cbar_ax.tick_params(labelsize=16)
            for label in cbar_ax.get_yticklabels():
                label.set_fontsize(30)
                label.set_fontweight('bold')
            # è®¾ç½® colorbar æ ‡ç­¾
            if cbar_ax.get_ylabel():
                cbar_ax.set_ylabel(cbar_ax.get_ylabel(), fontsize=30, fontweight='bold')
                # cbar_ax.yaxis.set_label_coords(2.3, 0.5)  # å¯é€‰ï¼šè°ƒæ•´ colorbar æ ‡é¢˜ä½ç½®
        # è°ƒæ•´å¸ƒå±€ä»¥é¿å…æ ‡ç­¾è¢«æˆªæ–­
        plt.tight_layout()
        
        plt.savefig(out_path1+'\\{}'.format(joint_class)+"\\åˆ†åŒº{}åœŸå£¤åˆ†ç±»{}_delta_sm_two_dependence.png".format(fenqu_id,joint_class), dpi=300, bbox_inches='tight')
        plt.close()
        # æ˜¾ç¤ºå›¾åƒ
        # plt.show()
      
