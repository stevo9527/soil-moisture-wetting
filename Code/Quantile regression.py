# -*- coding: utf-8 -*-
"""
Created on Mon Dec 15 17:58:41 2025

@author: fupf
"""

    
#%%
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf
import statsmodels.api as sm
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
# import sns
import os
from adjustText import adjust_text
import matplotlib.patheffects as pe
#%%
# ---------------------------------------------------------
# 1. æ•°æ®å‡†å¤‡ (åŸºäºæ‚¨æä¾›çš„ JSON æ•°æ®)
# ---------------------------------------------------------

joint_class='Loam_1'

full_dir = os.path.join(out_path1, joint_class)
# os.makedirs(full_dir)
# print(f"æ–‡ä»¶å¤¹ '{full_dir}' å·²åˆ›å»ºã€‚")

class_data = data_merge1[data_merge1['joint_class'] == joint_class]


#%%

fenqu_ids = sorted(class_data['zone'].unique())
fenqu_ids = [x for x in fenqu_ids if x != 5]

sector_map = {1: "A", 2: "B", 3: "C", 4: "D", 7: "F", 6: "G", 9: "H", 8: "I"}



for fenqu_id in fenqu_ids:
    print(f"\n=== å¤„ç†åˆ†åŒº {fenqu_id} ===")
    # fenqu_id=1.0

    
    # æå–å½“å‰åˆ†åŒºæ•°æ®
    fenqu_data = class_data[class_data['zone'] == int(fenqu_id)]
    fenqu_data_tiqu = fenqu_data[['zone', 'depth', 'TP', 'RSM', 'delta_sm']]
    

    
    df=fenqu_data_tiqu.copy()
    
    
    # 2. é…ç½®å‚æ•°
    config = {
        'delta_sm_threshold': 1,   # æé«˜ä¸€ç‚¹é˜ˆå€¼ä»¥ä¾¿æµ‹è¯•
        'tau': 0.5,                   # ä½¿ç”¨ä¸­ä½æ•°å›å½’æ›´ç¨³å®š
        # 'rsm_bins': np.arange(0, 1.05, 0.1),
        'min_samples_per_bin': 30,
        'min_rainfall': 1.0
    }
    
    
    
    # 1. é…ç½®å‚æ•°
    delta_sm_threshold = config.get('delta_sm_threshold', 1)
    tau = config.get('tau', 0.5)
    min_samples = config.get('min_samples_per_bin', 30)
    min_rainfall = config.get('min_rainfall', 1.0)
    
    # 2. æ•°æ®é¢„å¤„ç†
    df_clean = df.copy()
    
    # ç­›é€‰æœ‰æ•ˆæ¹¿åŒ–äº‹ä»¶
    df_valid = df_clean[
        (df_clean['TP'] >= min_rainfall) & 
        (df_clean['delta_sm'] > 0)
    ].copy()
    
    
    # æ­¥éª¤ 1: åªä¿ç•™ RSM < 120 çš„æ•°æ®ï¼ˆå¯é€‰ï¼šä¹Ÿå»ºè®® RSM >= 0ï¼‰
    df_valid = df_valid[(df_valid['RSM'] >= 0) & (df_valid['RSM'] < 120)].copy()
    
    depth_list=list(df_valid['depth'].unique())
    
    
    # === å…¨å±€å­—ä½“è®¾ç½®ï¼ˆç§»åˆ°æœ€å‰é¢ï¼Œåªéœ€ä¸€æ¬¡ï¼‰===
    import matplotlib as mpl
    
    mpl.rcParams['font.family'] = 'Times New Roman'
    mpl.rcParams['mathtext.fontset'] = 'custom' 
    # plt.rcParams['font.weight'] = 'bold'  
    mpl.rcParams['mathtext.rm'] = 'Times New Roman'
    mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'
    mpl.rcParams['mathtext.bf'] = 'Times New Roman'
    plt.rcParams["axes.unicode_minus"] = False
    plt.rcParams['text.usetex'] = False
    
    # === å®šä¹‰ depth é¡ºåºå’Œå¯¹åº”æ ·å¼ ===
    depth_list = ['0-7cm', '7-28cm', '28-100cm']
    markers = {
        '0-7cm': 'o',
        '7-28cm': '^',
        '28-100cm': 's'
    }
    colors = {
        '0-7cm': 'red',
        '7-28cm': 'blue',
        '28-100cm': 'green'
    }
    
    # === åˆ›å»ºç”»å¸ƒï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼ï¼‰===
    # fig, ax = plt.subplots(figsize=(10, 6), dpi=120)
    fig, ax = plt.subplots(figsize=(16, 8))

    # ç»™å³ä¾§å›¾ä¾‹é¢„ç•™ç©ºé—´ï¼ˆå…³é”®ï¼ï¼‰
    # fig.subplots_adjust(right=0.72)
    # fig.subplots_adjust(top=0.80)

    # === å­˜å‚¨æ‰€æœ‰ df_fit ç”¨äºåç»­åŠ æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰===
    all_df_fit = []

    fenqu_qr_df=[]
    fenqu_model_df=[]

    for depth in depth_list:
        
        # depth='7-28cm'
        
        df_valid_tiqu=df_valid[df_valid['depth']==depth]
        
        # if df_valid_tiqu.empty:
        #     print(f"Warning: No data for depth {depth}")
        # continue
    
        max_tp=df_valid_tiqu['TP'].max()
    
        # æ­¥éª¤ 2: å®šä¹‰è‡ªå®šä¹‰ bins å’Œ labels
        bins = [0, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]
        labels = [
            '0-30%',
            '30-40%',
            '40-50%',
            '50-60%',
            '60-70%',
            '70-80%',
            '80-90%',
            '90-100%',
            '100-110%',
            '110-120%'
        ]
        
        # æ­¥éª¤ 3: ä½¿ç”¨ pd.cut åˆ†ç®±
        df_valid_tiqu['RSM_bin'] = pd.cut(
            df_valid_tiqu['RSM'],
            bins=bins,
            labels=labels,
            include_lowest=True  # ç¡®ä¿ 0 è¢«åŒ…å«åœ¨ç¬¬ä¸€ä¸ª bin
        )
        
        # å¯é€‰ï¼šåˆ é™¤æœªè½å…¥ä»»ä½• bin çš„è¡Œï¼ˆç†è®ºä¸Šä¸ä¼šå‡ºç°ï¼Œå› å·²è¿‡æ»¤ RSM<120 ä¸” >=0ï¼‰
        df_valid_tiqu = df_valid_tiqu.dropna(subset=['RSM_bin']).reset_index(drop=True)
        
        min_bin=df_valid_tiqu['RSM_bin'].min()   
        max_bin=df_valid_tiqu['RSM_bin'].max()
        
        min_bin_split=min_bin.split("-")[0]
        max_bin_split=max_bin.split("-")[1]
        
        
        
        # ---------------------------------------------------------
        # 2. åˆ†ä½æ•°å›å½’è®¡ç®— TP_threshold
        # ---------------------------------------------------------
       
        
        # target_delta_sm_list=[1,2,3,4,5,6,7,8,9,10]
        target_delta_sm = 10  # æœ‰æ•ˆæ¹¿åŒ–ä¸´ç•Œå€¼ 1%
        
        # for target_delta_sm in target_delta_sm_list:
            
            # print(target_delta_sm)
        results_data = []
        bins = df_valid_tiqu['RSM_bin'].unique()
        tau = 0.5             # åˆ†ä½æ•°
        
        all_qr_result=[]
        # print(">>> åˆ†ä½æ•°å›å½’ (QR) è®¡ç®—ç»“æœ:")
        # print(f"{'Bin':<10} | {'Mean RSM':<10} | {'Intercept':<10} | {'Slope':<10} | {'TP_th (mm)':<10}")
        # print("-" * 65)
        
        for bin_label in bins:
            sub_df = df_valid_tiqu[df_valid_tiqu['RSM_bin'] == bin_label]
            
                
            col_index = sub_df.columns.get_loc('RSM_bin')
            RSM_bin = sub_df.iat[0, col_index]
            
            # QR æ¨¡å‹: delta_sm ~ TP
            mod = smf.quantreg('delta_sm ~ TP', sub_df)
            res = mod.fit(q=tau)
            
            beta_0 = res.params['Intercept']
            beta_1 = res.params['TP']
            
            # è®¡ç®—é˜ˆå€¼: TP_th = (1 - beta_0) / beta_1
            tp_th = (target_delta_sm - beta_0) / beta_1
            # print(tp_th)
            
            if 0 < tp_th < max_tp: # è®¡ç®—RSMåŒºé—´ä¸­ç‚¹ 
                mean_rsm = sub_df['RSM'].mean()
                
                results_data.append([mean_rsm, tp_th,RSM_bin])
                
                qr_results={
                    "depth":depth,
                    "Bin":bin_label,
                    "Mean RSM":round(mean_rsm,2),
                    "Intercept":round(beta_0,4),
                    "Slope":round(beta_1,4),
                    "TP_th (mm)":round(tp_th,4)
                    
                    }
            
                all_qr_result.append(qr_results)
            
                # print(f"{bin_label:<10} | {mean_rsm:<10.2f} | {beta_0:<10.4f} | {beta_1:<10.4f} | {tp_th:<10.4f}")
            
        qr_result_df=pd.DataFrame(all_qr_result)
            
        fenqu_qr_df.append(qr_result_df)
        
            
            # è½¬æ¢ä¸º DataFrame ç”¨äºæ‹Ÿåˆ
        df_fit = pd.DataFrame(results_data, columns=['x', 'y','RSM_bin'])
        # æŒ‰ RSM ä»å°åˆ°å¤§æ’åº
        df_fit = df_fit.sort_values(by='x')
        
        
        all_df_fit.append((depth, df_fit))  # ä¿å­˜ç”¨äºåŠ æ ‡ç­¾
         
            
        X = df_fit['x'].values
        Y = df_fit['y'].values
            
        # ---------------------------------------------------------
        # 3. æ›²çº¿æ‹Ÿåˆä¸ç»Ÿè®¡æ£€éªŒ (çº¿æ€§åŒ–æ–¹æ³•)
        # ---------------------------------------------------------
        
        # A. æŒ‡æ•°è¡°å‡æ¨¡å‹: Y = a * e^(b * X)  =>  ln(Y) = ln(a) + b * X
        #    ä»¤ Y' = ln(Y), A = ln(a), B = b
        df_fit['ln_y'] = np.log(df_fit['y'])
        exp_mod = smf.ols('ln_y ~ x', data=df_fit).fit()
        
        exp_a = np.exp(exp_mod.params['Intercept'])
        exp_b = exp_mod.params['x']
        exp_r2 = exp_mod.rsquared
        exp_p_val = exp_mod.pvalues['x']  # æ–œç‡çš„æ˜¾è‘—æ€§
        
        # print(f"\n>>> æŒ‡æ•°æ¨¡å‹æ‹Ÿåˆç»“æœ (Exponential):")
        # print(f"Eq: TP_th = {exp_a:.4f} * e^({exp_b:.4f} * RSM)")
        # print(f"R2: {exp_r2:.4f}, P-value: {exp_p_val:.4e}")
        
        # B. å¹‚å¾‹æ¨¡å‹: Y = a * X^b  =>  ln(Y) = ln(a) + b * ln(X)
        #    ä»¤ Y' = ln(Y), X' = ln(X), A = ln(a), B = b
        df_fit['ln_x'] = np.log(df_fit['x'])
        pow_mod = smf.ols('ln_y ~ ln_x', data=df_fit).fit()
        
        pow_a = np.exp(pow_mod.params['Intercept'])
        pow_b = pow_mod.params['ln_x']
        pow_r2 = pow_mod.rsquared
        pow_p_val = pow_mod.pvalues['ln_x']
        
        # print(f"\n>>> å¹‚å¾‹æ¨¡å‹æ‹Ÿåˆç»“æœ (Power Law):")
        # print(f"Eq: TP_th = {pow_a:.4f} * RSM ^ ({pow_b:.4f})")
        # print(f"R2: {pow_r2:.4f}, P-value: {pow_p_val:.4e}")
        
        # ---------------------------------------------------------
        # 2. å¤šé¡¹å¼å›å½’æ¨¡å‹ (Quadratic Model)
        # æ¨¡å‹å…¬å¼: Y = beta_0 + beta_1 * X + beta_2 * X^2
        # ---------------------------------------------------------
        # ä½¿ç”¨ statsmodels çš„å…¬å¼æ¥å£ï¼ŒI(RSM**2) è¡¨ç¤º RSM çš„å¹³æ–¹é¡¹
        poly_mod = smf.ols(formula='y ~ x + I(x**2)', data=df_fit).fit()
        
        # æå–å‚æ•°
        beta_0 = poly_mod.params['Intercept']     # æˆªè· c
        beta_1 = poly_mod.params['x']           # ä¸€æ¬¡é¡¹ç³»æ•° b
        beta_2 = poly_mod.params['I(x ** 2)']   # äºŒæ¬¡é¡¹ç³»æ•° a
        r_squared = poly_mod.rsquared             # R2
        p_values = poly_mod.pvalues               # På€¼
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        # print(">>> å¤šé¡¹å¼æ¨¡å‹ (äºŒæ¬¡) æ‹Ÿåˆç»“æœ:")
        # print(f"æ–¹ç¨‹: y = {beta_2:.6f} * x^2 + {beta_1:.6f} * x + {beta_0:.6f}")
        # print(f"R-squared (R2): {r_squared:.4f}")
        # print(f"P-values:\n{p_values}")
        
        muti_model_result={
            "depth":depth,
            "Exp_Eq":f"TP_th = {exp_a:.4f} * e^({exp_b:.4f} * RSM)",
            "Exp_R2":f"{pow_r2:.4f}",
            "Exp_P-value":f"{pow_p_val:.4e}",
            "Pow_Eq":f"TP_th = {pow_a:.4f} * RSM ^ ({pow_b:.4f})",
            "Pow_R2":f"{pow_r2:.4f}",
            "Pow_P-value":f"{pow_p_val:.4e}",
            "Pol_Eq":f"y = {beta_2:.6f} * x^2 + {beta_1:.6f} * x + {beta_0:.6f}",
            "Pol_R2":f"{r_squared:.4f}",
            "Pol_P-value":f"{p_values[2]:.4f}",
            }
        
        muti_result_df=pd.DataFrame([muti_model_result])
        
        fenqu_model_df.append(muti_result_df)
        
        

        # ---------------------------------------------------------
        # 4. ç»˜å›¾ä»£ç 
        # ---------------------------------------------------------
        # fig, ax = plt.subplots(figsize=(16, 8))
        
        
        # 2. ç”Ÿæˆå¹³æ»‘æ›²çº¿æ•°æ®
        x_smooth = np.linspace(X.min() * 0.95, X.max() * 1.05, 100)
        
        # è®¡ç®—æ‹Ÿåˆå€¼
        y_exp_smooth = exp_a * np.exp(exp_b * x_smooth)
        y_pow_smooth = pow_a * np.power(x_smooth, pow_b)
        
        # ä»£å…¥äºŒæ¬¡æ–¹ç¨‹è®¡ç®— y
        y_pol_smooth = beta_2 * (x_smooth**2) + beta_1 * x_smooth + beta_0
        
        
        # ===============================
        # 6. æ¨¡å‹é›†åˆï¼ˆæ ¸å¿ƒï¼‰
        #    ğŸ‘‰ ä¼˜å…ˆ P â†’ å†æ¯” RÂ²
        # ===============================
        model_pool = {
            'Exponential Model': {
                'p': exp_p_val,
                'r2': exp_r2,
                'y': y_exp_smooth
            },
            'Power Model': {
                'p': pow_p_val,
                'r2': pow_r2,
                'y': y_pow_smooth
            },
            'Polynomial Model': {
                'p': p_values[2],
                'r2': r_squared,
                'y': y_pol_smooth
            }
        }
        
        # ===============================
        # 7. æ¨¡å‹ä¼˜é€‰ï¼ˆP æœ€å° â†’ RÂ² æœ€å¤§ï¼‰
        # ===============================
        # best_model_name, best_model = sorted(
        #     model_pool.items(),
        #     key=lambda item: (item[1]['p'], -item[1]['r2'])
            
        # )[0]
        
        #ä¼˜å…ˆ RÂ² â†’ å†æ¯” P
        best_model_name, best_model = sorted(
            model_pool.items(),
            key=lambda item: (-item[1]['r2'], item[1]['p'])
        )[0]
        
        best_p  = best_model['p']
        best_r2 = best_model['r2']
        best_y  = best_model['y']

        # ===============================
        # 8. label_text è‡ªåŠ¨åŒ¹é…æ¨¡å‹ç±»å‹
        # ===============================
        if best_p < 0.05:
            p_label = 'P<0.05'
        elif best_p < 0.1:
            p_label = 'P<0.1'
        else:
            p_label = ''
        
        # model_name_tex = best_model_name.replace(' ', r'~')

        # label_text = rf'$\mathbf{{{depth} : \mathrm{{{model_name_tex}}},\ R^2 = {best_r2:.3f}}}$'

        # label_text = rf'$\mathbf{{{depth} : \text{{{best_model_name}}},\ R^2 = {best_r2:.3f}}}$'
        label_text = rf'${depth} : \text{{{best_model_name}}},\ R^2 = {best_r2:.3f}$'

        # label_text = rf'$\mathbf{{{depth} : {best_model_name},\ R^2 = {best_r2:.3f}}}$'
        if p_label:
            label_text += f', {p_label}'
        
        # ===============================
        # 9. ç»˜å›¾
        # ===============================
        
        ax.plot(
            x_smooth,
            best_y,
            color=colors[depth],
            linewidth=2,
            label=label_text,
            zorder=1
        )
        
        ax.scatter(
            X, Y,
            color='black',
            s=80,
            edgecolors='black',
            zorder=5,
            label='Calculated Thresholds (QR, Ï„=0.5)'
        )
        

    offset_map = {
        '0-7cm': (0, -8),
        '7-28cm': (0, 2),
        '28-100cm': (0, 2)
    }
    
    texts = []
    for depth, df_fit in all_df_fit:
        dx, dy = offset_map[depth]
        for _, row in df_fit.iterrows():
            texts.append(
                ax.text(
                    row['x'] + dx,
                    row['y'] + dy,
                    f"{row['y']:.2f}",
                    fontsize=18,
                    fontweight='bold',
                    zorder=10,
                    path_effects=[
                        pe.withStroke(linewidth=3, foreground='white')
                    ]
                )
            )

    
    adjust_text(
        texts,
        ax=ax,
        expand_points=(1.5, 3.5),
        expand_text=(1.5, 2.5),
        # arrowprops=dict(arrowstyle='-', lw=0.6, color='0.3'),
        force_points=1.2,
        force_text=1.0,
        autoalign=True,
        only_move={'points': 'y', 'text': 'y'}  # â—åªå…è®¸ä¸Šä¸‹ç§»åŠ¨
    )


    
    # === è®¾ç½®åˆ»åº¦æ ‡ç­¾å¤§å°å’ŒåŠ ç²— ===
    ax.tick_params(axis='both', which='major', labelsize=20, width=1, color='black')
    ax.tick_params(axis='y', which='major', labelsize=20, width=1, color='black')

    # é‡æ–°è®¾ç½® y è½´æ ‡ç­¾ä»¥æ”¯æŒ fontweight
    y_labels = [label.get_text() for label in ax.get_yticklabels()]
    ax.set_yticklabels(y_labels, fontsize=20, fontweight='bold')

    # å¯é€‰ï¼šx è½´æ ‡ç­¾ä¹ŸåŠ ç²—
    x_labels = [label.get_text() for label in ax.get_xticklabels()]
    ax.set_xticklabels(x_labels, fontsize=20, fontweight='bold')
    ax.xaxis.set_label_coords(0.5, -0.15)  # è°ƒæ•´ -0.15 åˆ°ä½ æƒ³è¦çš„ç¡®åˆ‡ä½ç½®
    
    # === å›¾è¡¨è£…é¥° ===
    # ax.set_title(f'Precipitation threshold at a {target_delta_sm}% increase in soil relative humidity gradient', fontsize=14)
    ax.set_xlabel('Soil Relative Humidity (%)', fontsize=20, fontweight='bold')
    ax.set_ylabel('Precipitation Threshold (mm)', fontsize=20, fontweight='bold')
    ax.grid(True, linestyle=':', alpha=0.6)
    
    # åŒºåŸŸæ ‡ç­¾ï¼ˆå‡è®¾ fenqu_id, joint_class, sector_map å·²å®šä¹‰ï¼‰
    zone_label = sector_map.get(fenqu_id, str(fenqu_id))
    ax.text(
        0.2, 0.9, f'{joint_class} at zone {zone_label}',
        transform=ax.transAxes,
        fontsize=22,
        # fontweight='bold',
        fontname='Times New Roman',
        verticalalignment='bottom',
        horizontalalignment='right',
        color='black'
    )
    
    handles, labels = ax.get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    
    legend = ax.legend(
        
        by_label.values(),
        by_label.keys(),
        prop={
        'family': 'Times New Roman',
        'size': 22,
        'weight': 'normal'
            },
        # fontsize=22,
        # fontweight='bold',
        ncol=2,
        loc='upper center',
        bbox_to_anchor=(0.5, 1.25),   # ç´§è´´å³ä¾§
        borderaxespad=0.0,
        frameon=False
    )
    
    legend.get_frame().set_facecolor('none')  # æˆ–è€…ä½¿ç”¨ set_alpha(0) æ¥è¾¾åˆ°ç›¸åŒæ•ˆæœ
    
    # è®¾ç½®å›¾ä¾‹å­—ä½“
    for text in legend.get_texts():
        text.set_fontname('Times New Roman')  # ç¡®ä¿å­—ä½“æ­£ç¡®
        # text.set_weight('bold')                # å¼ºåˆ¶åŠ ç²—ï¼
        text.set_fontweight('normal')
        # text.set_size(22)                      # å¯é€‰ï¼šç»Ÿä¸€å­—å·
    
    
    plt.savefig(
    full_dir + "\\åœŸå£¤åˆ†ç±»{}åˆ†åŒº{}_{}-{}æ¹¿åº¦æ¢¯åº¦å¢åŠ {}é™æ°´é˜ˆå€¼.png"
    .format(joint_class, fenqu_id, min_bin_split, max_bin_split, target_delta_sm),
    dpi=300,
    bbox_inches='tight'
                )
    
    plt.close()  

    fenqu_qr_df_concat=pd.concat(fenqu_qr_df)
    fenqu_mdoel_df_concat=pd.concat(fenqu_model_df)
    
    fenqu_qr_df_concat.to_csv(full_dir+'\\åˆ†åŒº{}åœŸå£¤åˆ†ç±»{}æ¹¿åº¦æ¢¯åº¦å¢åŠ {}QRå›å½’ç»“æœ.csv'.format(fenqu_id,joint_class,target_delta_sm),encoding='utf_8_sig', index=False, header=True)
    fenqu_mdoel_df_concat.to_csv(full_dir+'\\åˆ†åŒº{}åœŸå£¤åˆ†ç±»{}æ¢¯åº¦æ¹¿åº¦å¢åŠ {}å¤šæ¨¡å‹æ‹Ÿåˆç»“æœ.csv'.format(fenqu_id,joint_class,target_delta_sm),encoding='utf_8_sig', index=False, header=True)
        


df=class_data.copy()


# 2. é…ç½®å‚æ•°
config = {
    'delta_sm_threshold': 1,   # æé«˜ä¸€ç‚¹é˜ˆå€¼ä»¥ä¾¿æµ‹è¯•
    'tau': 0.5,                   # ä½¿ç”¨ä¸­ä½æ•°å›å½’æ›´ç¨³å®š
    # 'rsm_bins': np.arange(0, 1.05, 0.1),
    'min_samples_per_bin': 30,
    'min_rainfall': 1.0
}



# 1. é…ç½®å‚æ•°
delta_sm_threshold = config.get('delta_sm_threshold', 1)
tau = config.get('tau', 0.5)
min_samples = config.get('min_samples_per_bin', 30)
min_rainfall = config.get('min_rainfall', 1.0)

# 2. æ•°æ®é¢„å¤„ç†
df_clean = df.copy()

# ç­›é€‰æœ‰æ•ˆæ¹¿åŒ–äº‹ä»¶
df_valid = df_clean[
    (df_clean['TP'] >= min_rainfall) & 
    (df_clean['delta_sm'] > 0)
].copy()


# æ­¥éª¤ 1: åªä¿ç•™ RSM < 120 çš„æ•°æ®ï¼ˆå¯é€‰ï¼šä¹Ÿå»ºè®® RSM >= 0ï¼‰
df_valid = df_valid[(df_valid['RSM'] >= 0) & (df_valid['RSM'] < 120)].copy()

depth_list=list(df_valid['depth'].unique())


# === å…¨å±€å­—ä½“è®¾ç½®ï¼ˆç§»åˆ°æœ€å‰é¢ï¼Œåªéœ€ä¸€æ¬¡ï¼‰===
import matplotlib as mpl

mpl.rcParams['font.family'] = 'Times New Roman'
mpl.rcParams['mathtext.fontset'] = 'custom' 
# plt.rcParams['font.weight'] = 'bold'  
mpl.rcParams['mathtext.rm'] = 'Times New Roman'
mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'
mpl.rcParams['mathtext.bf'] = 'Times New Roman'
plt.rcParams["axes.unicode_minus"] = False
plt.rcParams['text.usetex'] = False

# === å®šä¹‰ depth é¡ºåºå’Œå¯¹åº”æ ·å¼ ===
depth_list = ['0-7cm', '7-28cm', '28-100cm']
markers = {
    '0-7cm': 'o',
    '7-28cm': '^',
    '28-100cm': 's'
}
colors = {
    '0-7cm': 'red',
    '7-28cm': 'blue',
    '28-100cm': 'green'
}

# === åˆ›å»ºç”»å¸ƒï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼ï¼‰===
# fig, ax = plt.subplots(figsize=(10, 6), dpi=120)
fig, ax = plt.subplots(figsize=(18, 8))

# ç»™å³ä¾§å›¾ä¾‹é¢„ç•™ç©ºé—´ï¼ˆå…³é”®ï¼ï¼‰
# fig.subplots_adjust(right=0.72)
# fig.subplots_adjust(top=0.80)

# === å­˜å‚¨æ‰€æœ‰ df_fit ç”¨äºåç»­åŠ æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰===
all_df_fit = []

all_qr_df=[]
all_model_df=[]

for depth in depth_list:
    
    # depth='7-28cm'
    
    df_valid_tiqu=df_valid[df_valid['depth']==depth]
    
    # if df_valid_tiqu.empty:
    #     print(f"Warning: No data for depth {depth}")
    # continue

    max_tp=df_valid_tiqu['TP'].max()

    # æ­¥éª¤ 2: å®šä¹‰è‡ªå®šä¹‰ bins å’Œ labels
    bins = [0, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]
    labels = [
        '0-30%',
        '30-40%',
        '40-50%',
        '50-60%',
        '60-70%',
        '70-80%',
        '80-90%',
        '90-100%',
        '100-110%',
        '110-120%'
    ]
    
    # æ­¥éª¤ 3: ä½¿ç”¨ pd.cut åˆ†ç®±
    df_valid_tiqu['RSM_bin'] = pd.cut(
        df_valid_tiqu['RSM'],
        bins=bins,
        labels=labels,
        include_lowest=True  # ç¡®ä¿ 0 è¢«åŒ…å«åœ¨ç¬¬ä¸€ä¸ª bin
    )
    
    # å¯é€‰ï¼šåˆ é™¤æœªè½å…¥ä»»ä½• bin çš„è¡Œï¼ˆç†è®ºä¸Šä¸ä¼šå‡ºç°ï¼Œå› å·²è¿‡æ»¤ RSM<120 ä¸” >=0ï¼‰
    df_valid_tiqu = df_valid_tiqu.dropna(subset=['RSM_bin']).reset_index(drop=True)
    
    min_bin=df_valid_tiqu['RSM_bin'].min()   
    max_bin=df_valid_tiqu['RSM_bin'].max()
    
    min_bin_split=min_bin.split("-")[0]
    max_bin_split=max_bin.split("-")[1]
    
    
    
    # ---------------------------------------------------------
    # 2. åˆ†ä½æ•°å›å½’è®¡ç®— TP_threshold
    # ---------------------------------------------------------
   
    
    # target_delta_sm_list=[1,2,3,4,5,6,7,8,9,10]
    target_delta_sm = 10  # æœ‰æ•ˆæ¹¿åŒ–ä¸´ç•Œå€¼ 1%
    
    # for target_delta_sm in target_delta_sm_list:
        
        # print(target_delta_sm)
    results_data = []
    bins = df_valid_tiqu['RSM_bin'].unique()
    tau = 0.5             # åˆ†ä½æ•°
    
    all_qr_result=[]
    # print(">>> åˆ†ä½æ•°å›å½’ (QR) è®¡ç®—ç»“æœ:")
    # print(f"{'Bin':<10} | {'Mean RSM':<10} | {'Intercept':<10} | {'Slope':<10} | {'TP_th (mm)':<10}")
    # print("-" * 65)
    
    for bin_label in bins:
        sub_df = df_valid_tiqu[df_valid_tiqu['RSM_bin'] == bin_label]
        
            
        col_index = sub_df.columns.get_loc('RSM_bin')
        RSM_bin = sub_df.iat[0, col_index]
        
        # QR æ¨¡å‹: delta_sm ~ TP
        mod = smf.quantreg('delta_sm ~ TP', sub_df)
        res = mod.fit(q=tau)
        
        beta_0 = res.params['Intercept']
        beta_1 = res.params['TP']
        
        # è®¡ç®—é˜ˆå€¼: TP_th = (1 - beta_0) / beta_1
        tp_th = (target_delta_sm - beta_0) / beta_1
        # print(tp_th)
        
        if 0 < tp_th < max_tp: # è®¡ç®—RSMåŒºé—´ä¸­ç‚¹ 
            mean_rsm = sub_df['RSM'].mean()
            
            results_data.append([mean_rsm, tp_th,RSM_bin])
            
            qr_results={
                "depth":depth,
                "Bin":bin_label,
                "Mean RSM":round(mean_rsm,2),
                "Intercept":round(beta_0,4),
                "Slope":round(beta_1,4),
                "TP_th (mm)":round(tp_th,4)
                
                }
        
        all_qr_result.append(qr_results)
            
    qr_result_df=pd.DataFrame(all_qr_result)
        
    all_qr_df.append(qr_result_df)        
            # print(f"{bin_label:<10} | {mean_rsm:<10.2f} | {beta_0:<10.4f} | {beta_1:<10.4f} | {tp_th:<10.4f}")
        
        
            
        # è½¬æ¢ä¸º DataFrame ç”¨äºæ‹Ÿåˆ
    df_fit = pd.DataFrame(results_data, columns=['x', 'y','RSM_bin'])
    # æŒ‰ RSM ä»å°åˆ°å¤§æ’åº
    df_fit = df_fit.sort_values(by='x')
    
    
    all_df_fit.append((depth, df_fit))  # ä¿å­˜ç”¨äºåŠ æ ‡ç­¾
     
        
    X = df_fit['x'].values
    Y = df_fit['y'].values
        
    # ---------------------------------------------------------
    # 3. æ›²çº¿æ‹Ÿåˆä¸ç»Ÿè®¡æ£€éªŒ (çº¿æ€§åŒ–æ–¹æ³•)
    # ---------------------------------------------------------
    
    # A. æŒ‡æ•°è¡°å‡æ¨¡å‹: Y = a * e^(b * X)  =>  ln(Y) = ln(a) + b * X
    #    ä»¤ Y' = ln(Y), A = ln(a), B = b
    df_fit['ln_y'] = np.log(df_fit['y'])
    exp_mod = smf.ols('ln_y ~ x', data=df_fit).fit()
    
    exp_a = np.exp(exp_mod.params['Intercept'])
    exp_b = exp_mod.params['x']
    exp_r2 = exp_mod.rsquared
    exp_p_val = exp_mod.pvalues['x']  # æ–œç‡çš„æ˜¾è‘—æ€§
    
    # print(f"\n>>> æŒ‡æ•°æ¨¡å‹æ‹Ÿåˆç»“æœ (Exponential):")
    # print(f"Eq: TP_th = {exp_a:.4f} * e^({exp_b:.4f} * RSM)")
    # print(f"R2: {exp_r2:.4f}, P-value: {exp_p_val:.4e}")
    
    # B. å¹‚å¾‹æ¨¡å‹: Y = a * X^b  =>  ln(Y) = ln(a) + b * ln(X)
    #    ä»¤ Y' = ln(Y), X' = ln(X), A = ln(a), B = b
    df_fit['ln_x'] = np.log(df_fit['x'])
    pow_mod = smf.ols('ln_y ~ ln_x', data=df_fit).fit()
    
    pow_a = np.exp(pow_mod.params['Intercept'])
    pow_b = pow_mod.params['ln_x']
    pow_r2 = pow_mod.rsquared
    pow_p_val = pow_mod.pvalues['ln_x']
    
    # print(f"\n>>> å¹‚å¾‹æ¨¡å‹æ‹Ÿåˆç»“æœ (Power Law):")
    # print(f"Eq: TP_th = {pow_a:.4f} * RSM ^ ({pow_b:.4f})")
    # print(f"R2: {pow_r2:.4f}, P-value: {pow_p_val:.4e}")
    
    # ---------------------------------------------------------
    # 2. å¤šé¡¹å¼å›å½’æ¨¡å‹ (Quadratic Model)
    # æ¨¡å‹å…¬å¼: Y = beta_0 + beta_1 * X + beta_2 * X^2
    # ---------------------------------------------------------
    # ä½¿ç”¨ statsmodels çš„å…¬å¼æ¥å£ï¼ŒI(RSM**2) è¡¨ç¤º RSM çš„å¹³æ–¹é¡¹
    poly_mod = smf.ols(formula='y ~ x + I(x**2)', data=df_fit).fit()
    
    # æå–å‚æ•°
    beta_0 = poly_mod.params['Intercept']     # æˆªè· c
    beta_1 = poly_mod.params['x']           # ä¸€æ¬¡é¡¹ç³»æ•° b
    beta_2 = poly_mod.params['I(x ** 2)']   # äºŒæ¬¡é¡¹ç³»æ•° a
    r_squared = poly_mod.rsquared             # R2
    p_values = poly_mod.pvalues               # På€¼
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    # print(">>> å¤šé¡¹å¼æ¨¡å‹ (äºŒæ¬¡) æ‹Ÿåˆç»“æœ:")
    # print(f"æ–¹ç¨‹: y = {beta_2:.6f} * x^2 + {beta_1:.6f} * x + {beta_0:.6f}")
    # print(f"R-squared (R2): {r_squared:.4f}")
    # print(f"P-values:\n{p_values}")
    
    muti_model_result={
        "depth":depth,
        "Exp_Eq":f"TP_th = {exp_a:.4f} * e^({exp_b:.4f} * RSM)",
        "Exp_R2":f"{pow_r2:.4f}",
        "Exp_P-value":f"{pow_p_val:.4e}",
        "Pow_Eq":f"TP_th = {pow_a:.4f} * RSM ^ ({pow_b:.4f})",
        "Pow_R2":f"{pow_r2:.4f}",
        "Pow_P-value":f"{pow_p_val:.4e}",
        "Pol_Eq":f"y = {beta_2:.6f} * x^2 + {beta_1:.6f} * x + {beta_0:.6f}",
        "Pol_R2":f"{r_squared:.4f}",
        "Pol_P-value":f"{p_values[2]:.4f}",
        }
    
    muti_result_df=pd.DataFrame([muti_model_result])
    
    all_model_df.append(muti_result_df)
    

    # ---------------------------------------------------------
    # 4. ç»˜å›¾ä»£ç 
    # ---------------------------------------------------------
    # fig, ax = plt.subplots(figsize=(16, 8))
    
    
    # 2. ç”Ÿæˆå¹³æ»‘æ›²çº¿æ•°æ®
    x_smooth = np.linspace(X.min() * 0.95, X.max() * 1.05, 100)
    
    # è®¡ç®—æ‹Ÿåˆå€¼
    y_exp_smooth = exp_a * np.exp(exp_b * x_smooth)
    y_pow_smooth = pow_a * np.power(x_smooth, pow_b)
    
    # ä»£å…¥äºŒæ¬¡æ–¹ç¨‹è®¡ç®— y
    y_pol_smooth = beta_2 * (x_smooth**2) + beta_1 * x_smooth + beta_0
    
    
    # ===============================
    # 6. æ¨¡å‹é›†åˆï¼ˆæ ¸å¿ƒï¼‰
    #    ğŸ‘‰ ä¼˜å…ˆ P â†’ å†æ¯” RÂ²
    # ===============================
    model_pool = {
        'Exponential Model': {
            'p': exp_p_val,
            'r2': exp_r2,
            'y': y_exp_smooth
        },
        'Power Model': {
            'p': pow_p_val,
            'r2': pow_r2,
            'y': y_pow_smooth
        },
        'Polynomial Model': {
            'p': p_values[2],
            'r2': r_squared,
            'y': y_pol_smooth
        }
    }
    
    # ===============================
    # 7. æ¨¡å‹ä¼˜é€‰ï¼ˆP æœ€å° â†’ RÂ² æœ€å¤§ï¼‰
    # ===============================
    # best_model_name, best_model = sorted(
    #     model_pool.items(),
    #     key=lambda item: (item[1]['p'], -item[1]['r2'])
        
    # )[0]
    
    #ä¼˜å…ˆ RÂ² â†’ å†æ¯” P
    best_model_name, best_model = sorted(
        model_pool.items(),
        key=lambda item: (-item[1]['r2'], item[1]['p'])
    )[0]
    
    best_p  = best_model['p']
    best_r2 = best_model['r2']
    best_y  = best_model['y']

    # ===============================
    # 8. label_text è‡ªåŠ¨åŒ¹é…æ¨¡å‹ç±»å‹
    # ===============================
    if best_p < 0.05:
        p_label = 'P<0.05'
    elif best_p < 0.1:
        p_label = 'P<0.1'
    else:
        p_label = ''
    
   
    label_text = rf'${depth} : \text{{{best_model_name}}},\ R^2 = {best_r2:.3f}$'

    # label_text = rf'$\mathbf{{{depth} : {best_model_name},\ R^2 = {best_r2:.3f}}}$'
    if p_label:
        label_text += f', {p_label}'
    
    # ===============================
    # 9. ç»˜å›¾
    # ===============================
    
    ax.plot(
        x_smooth,
        best_y,
        color=colors[depth],
        linewidth=2,
        label=label_text,
        zorder=1
    )
    
    ax.scatter(
        X, Y,
        color='black',
        s=80,
        edgecolors='black',
        zorder=5,
        label='Calculated Thresholds (QR, Ï„=0.5)'
    )
    


offset_map = {
    '0-7cm': (0, -8),
    '7-28cm': (0, 2),
    '28-100cm': (0, 2)
}

texts = []
for depth, df_fit in all_df_fit:
    dx, dy = offset_map[depth]
    for _, row in df_fit.iterrows():
        texts.append(
            ax.text(
                row['x'] + dx,
                row['y'] + dy,
                f"{row['y']:.2f}",
                fontsize=22,
                fontweight='bold',
                zorder=10,
                path_effects=[
                    pe.withStroke(linewidth=3, foreground='white')
                ]
            )
        )

adjust_text(
    texts,
    ax=ax,
    expand_points=(1.5, 3.5),
    expand_text=(1.5, 2.5),
    # arrowprops=dict(arrowstyle='-', lw=0.6, color='0.3'),
    force_points=1.2,
    force_text=1.0,
    autoalign=True,
    only_move={'points': 'y', 'text': 'y'}  # â—åªå…è®¸ä¸Šä¸‹ç§»åŠ¨
)



# === è®¾ç½®åˆ»åº¦æ ‡ç­¾å¤§å°å’ŒåŠ ç²— ===
ax.tick_params(axis='both', which='major', labelsize=25, width=1, color='black')
ax.tick_params(axis='y', which='major', labelsize=25, width=1, color='black')

# é‡æ–°è®¾ç½® y è½´æ ‡ç­¾ä»¥æ”¯æŒ fontweight
y_labels = [label.get_text() for label in ax.get_yticklabels()]
ax.set_yticklabels(y_labels, fontsize=25, fontweight='bold')

# å¯é€‰ï¼šx è½´æ ‡ç­¾ä¹ŸåŠ ç²—
x_labels = [label.get_text() for label in ax.get_xticklabels()]
ax.set_xticklabels(x_labels, fontsize=25, fontweight='bold')
ax.xaxis.set_label_coords(0.5, -0.15)  # è°ƒæ•´ -0.15 åˆ°ä½ æƒ³è¦çš„ç¡®åˆ‡ä½ç½®

# === å›¾è¡¨è£…é¥° ===
# ax.set_title(f'Precipitation threshold at a {target_delta_sm}% increase in soil relative humidity gradient', fontsize=14)
ax.set_xlabel('Soil Relative Humidity (%)', fontsize=25, fontweight='bold')
ax.set_ylabel('Precipitation Threshold (mm)', fontsize=25, fontweight='bold')
ax.grid(True, linestyle=':', alpha=0.6)

# åŒºåŸŸæ ‡ç­¾ï¼ˆå‡è®¾ fenqu_id, joint_class, sector_map å·²å®šä¹‰ï¼‰
zone_label = sector_map.get(fenqu_id, str(fenqu_id))
ax.text(
    0.1, 0.9, f'{joint_class}',
    transform=ax.transAxes,
    fontsize=22,
    fontweight='bold',
    fontname='Times New Roman',
    verticalalignment='bottom',
    horizontalalignment='right',
    color='black'
)

handles, labels = ax.get_legend_handles_labels()
by_label = dict(zip(labels, handles))

legend = ax.legend(
    
    by_label.values(),
    by_label.keys(),
    prop={
    'family': 'Times New Roman',
    'size': 22,
    'weight': 'normal'
        },
    # fontsize=22,
    # fontweight='bold',
    ncol=2,
    loc='upper center',
    bbox_to_anchor=(0.5, 1.25),   # ç´§è´´å³ä¾§
    borderaxespad=0.0,
    frameon=False
)

legend.get_frame().set_facecolor('none')  # æˆ–è€…ä½¿ç”¨ set_alpha(0) æ¥è¾¾åˆ°ç›¸åŒæ•ˆæœ

# è®¾ç½®å›¾ä¾‹å­—ä½“
for text in legend.get_texts():
    text.set_fontname('Times New Roman')  # ç¡®ä¿å­—ä½“æ­£ç¡®
    # text.set_weight('bold')                # å¼ºåˆ¶åŠ ç²—ï¼
    text.set_fontweight('normal')
    # text.set_size(22)                      # å¯é€‰ï¼šç»Ÿä¸€å­—å·


plt.savefig(
full_dir + "\\åœŸå£¤åˆ†ç±»{}_{}-{}æ¹¿åº¦æ¢¯åº¦å¢åŠ {}é™æ°´é˜ˆå€¼.png"
.format(joint_class,  min_bin_split, max_bin_split, target_delta_sm),
dpi=300,
bbox_inches='tight'
            )

plt.close()          
    

all_qr_df_concat=pd.concat(all_qr_df)  
all_model_df_concat=pd.concat(all_model_df)  


        




